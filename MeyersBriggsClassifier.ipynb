{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Add:\n",
    "    * Extract more features\n",
    "    * add more to writeup sections after the train and eval section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joey Demple<br>\n",
    "Prof Hulden<br>\n",
    "LING 5800<br>\n",
    "Final Project<br>\n",
    "Dec 17, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Myers-Briggs Personality Type Classifier\n",
    "Earlier, I trained a classifier to predict which type out of the 16 possible MBTI personality types belongs to a person based on their last 50 online posts. The accuracy is about 27% for this holistic model with all 16 labels. Although this sounds like pretty bad accuracy when you consider that if we were to pick one personality type at random as a guess that would give us 6.25% accuracy. So we are doing quite a bit better than that.\n",
    "However, what I want to do here is create four separate classifiers and output a prediction for each one. Breaking this up should provide some interesting insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "\n",
    "# Classifiers to use in this notebook\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifiers to be fitted and evaluated\n",
    "classifiers = [MultinomialNB(), \n",
    "               LogisticRegression(), \n",
    "               # svm.SVC(kernel='rbf'), \n",
    "               Perceptron(), \n",
    "               tree.DecisionTreeClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ratio of train/test data\n",
    "split_ratio = 0.85\n",
    "\n",
    "# seed for random split of train/test data\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of data\n",
    "file = './data/mbti_1.csv'\n",
    "\n",
    "# Our data is the MBTI-Type dataset from Kaggle.com\n",
    "# https://www.kaggle.com/datasnaek/mbti-type/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Our Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_extract(filepath, split_ratio=0.85, seed=1):\n",
    "    loaded = pd.read_csv(filepath)\n",
    "    # print('Dataset size', loaded.shape, loaded.info)\n",
    "    # split into training, testing\n",
    "    train=loaded.sample(frac=split_ratio, random_state=seed)\n",
    "    test=loaded.drop(train.index)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_into_dichotomies(df):\n",
    "    # split ENTP or other personality type into four columns\n",
    "    df['dicho1'] = df.type.str[0]\n",
    "    df['dicho2'] = df.type.str[1]\n",
    "    df['dicho3'] = df.type.str[2]\n",
    "    df['dicho4'] = df.type.str[3]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_double_period(clean_str):\n",
    "    return clean_str.replace('..', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_delim(clean_str):\n",
    "    return clean_str.replace('|||', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_links(clean_str):\n",
    "    urlpattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(urlpattern, '*LINK*', clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_posts(posts_raw):\n",
    "    bow = []\n",
    "    if posts_raw.startswith('\"') or posts_raw.startswith(\"'\"):\n",
    "                # remove extra string quotes if exist\n",
    "        clean = posts_raw[1:-1]\n",
    "    else:\n",
    "        clean = posts_raw\n",
    "    clean = remove_double_period(clean)\n",
    "    clean = remove_delim(clean)\n",
    "    clean = replace_links(clean)\n",
    "    clean = word_tokenize(clean)   \n",
    "    return [c.lower() for c in clean]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab(df):\n",
    "    ## get vocabulary for a dataset, i.e. all possbile features\n",
    "    vocab = []\n",
    "    for row in df.itertuples():\n",
    "        vocab.extend(row.post_list)\n",
    "    return set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_one(x, vocab, dichotomy=False):\n",
    "    # take one training example (dataframe row) and return a sparse feature vector\n",
    "    # init feature vec with zeros\n",
    "    feature_dict = {}\n",
    "    count_keys = len(feature_dict.keys())\n",
    "    \n",
    "    # I know this part is really not elegant code. Rewriting these functions from\n",
    "    # scratch would be the next step I take.\n",
    "    if dichotomy == 1:  # if personality type is split into dichotomies\n",
    "        label = x.dicho1\n",
    "    elif dichotomy == 2:  # if personality type is split into dichotomies\n",
    "        label = x.dicho2\n",
    "    elif dichotomy == 3:  # if personality type is split into dichotomies\n",
    "        label = x.dicho3\n",
    "    elif dichotomy == 4:  # if personality type is split into dichotomies\n",
    "        label = x.dicho4\n",
    "    else:          # if personality type is not split e.g. INTJ\n",
    "        label = x.type\n",
    "    \n",
    "    raw_feat = x.post_list\n",
    "    for fx in x.post_list:\n",
    "        if fx in vocab:\n",
    "            feature_dict[fx] = 1  # One Hot Encoding\n",
    "    return label, feature_dict  # returns label and feature dict for a single training sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_dict(df, vocab, dichotomy=False):\n",
    "    # Create a feature dictionary for a dataset\n",
    "    X = []\n",
    "    y = []\n",
    "    for row in df.itertuples():\n",
    "        if dichotomy:\n",
    "            result = vectorize_one(row, vocab, dichotomy)\n",
    "        else:\n",
    "            result = vectorize_one(row, vocab)\n",
    "        y.append(result[0])\n",
    "        X.append(result[1])\n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_all(train, test, dichotomy=False):\n",
    "    vocab = get_vocab(train)\n",
    "    \n",
    "    if dichotomy:\n",
    "        # training data\n",
    "        y_train, X_train_dict = get_feature_dict(train, vocab, dichotomy)\n",
    "        X_train = vectorizer.fit_transform(X_train_dict)\n",
    "    \n",
    "        # testing data\n",
    "        y_test, X_test_dict = get_feature_dict(test, vocab, dichotomy)\n",
    "        X_test = vectorizer.transform(X_test_dict)\n",
    "    \n",
    "    else:\n",
    "        # training data\n",
    "        y_train, X_train_dict = get_feature_dict(train, vocab)\n",
    "        X_train = vectorizer.fit_transform(X_train_dict)\n",
    "    \n",
    "        # testing data\n",
    "        y_test, X_test_dict = get_feature_dict(test, vocab)\n",
    "        X_test = vectorizer.transform(X_test_dict)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate_one(classifier, X_train, y_train, X_test, y_test):\n",
    "    # fitting\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # accuracy\n",
    "    results = {}\n",
    "    y_hat_train = classifier.predict(X_train)\n",
    "    accur_train = sum(y_hat_train == y_train) / len(y_train)  # train accuracy\n",
    "    y_hat_test = classifier.predict(X_test)\n",
    "    accur_test = sum(y_hat_test == y_test) / len(y_test)  # test accuracy\n",
    "    results['accur_train'] = accur_train\n",
    "    results['accur_test'] = accur_test\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    for c in classifiers:\n",
    "        cname = str(c).split('(')[0]\n",
    "        print('Training '+cname+ '...')\n",
    "        results[cname] = fit_and_evaluate_one(c, X_train, y_train, X_test, y_test)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = load_and_extract(file, split_ratio, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "All Personality Types, i.e. all possible labels in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Personality_dichotomies = {1:{'E':0, 'I':0},\n",
    "                           2:{'N':0, 'S':0},\n",
    "                           3:{'F':0, 'T':0},\n",
    "                           4:{'J':0, 'P':0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split type into four dichotomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = split_into_dichotomies(train)\n",
    "test = split_into_dichotomies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of extra string quotes and tokenize into posts for each row in posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['post_list'] = train['posts'].apply(clean_posts)\n",
    "test['post_list'] = test['posts'].apply(clean_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Train and Evaluate\n",
    "I put all of these steps into one so that each model would run one at a time and overwrite the previous feature vectors. This should prevent using too much memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holistic Model<br>\n",
    "16 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.540354</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.500384</td>\n",
       "      <td>0.993355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.388163</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.273636</td>\n",
       "      <td>0.621779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "LogisticRegression        0.540354     1.000000\n",
       "Perceptron                0.500384     0.993355\n",
       "DecisionTreeClassifier    0.388163     1.000000\n",
       "MultinomialNB             0.273636     0.621779"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holistic_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "holistic_result = pd.DataFrame.from_dict(holistic_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "holistic_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The best accuracy is about 54% for the holistic model with all 16 labels (using Logistic Regression). Although this sounds like pretty bad accuracy when you consider that if we were to pick one personality type at random as a guess that would give us 6.25% accuracy. So we are doing quite a bit better than that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dichotomized Model<br>\n",
    "First Dichotomy: E or I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.833205</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.795542</td>\n",
       "      <td>0.971793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.790161</td>\n",
       "      <td>0.897884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.759416</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "LogisticRegression        0.833205     1.000000\n",
       "Perceptron                0.795542     0.971793\n",
       "MultinomialNB             0.790161     0.897884\n",
       "DecisionTreeClassifier    0.759416     1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test, dichotomy=1)\n",
    "dicho1_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "dicho1_result = pd.DataFrame.from_dict(dicho1_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "dicho1_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Dichotomy: N or S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.858570</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.848578</td>\n",
       "      <td>0.989829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.840123</td>\n",
       "      <td>0.890155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.814758</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "LogisticRegression        0.858570     1.000000\n",
       "Perceptron                0.848578     0.989829\n",
       "MultinomialNB             0.840123     0.890155\n",
       "DecisionTreeClassifier    0.814758     1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test, dichotomy=2)\n",
    "dicho2_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "dicho2_result = pd.DataFrame.from_dict(dicho2_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "dicho2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Dichotomy: F or T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.807840</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.787087</td>\n",
       "      <td>0.983184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.782475</td>\n",
       "      <td>0.972471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.670254</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "LogisticRegression        0.807840     1.000000\n",
       "Perceptron                0.787087     0.983184\n",
       "MultinomialNB             0.782475     0.972471\n",
       "DecisionTreeClassifier    0.670254     1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test, dichotomy=3)\n",
    "dicho3_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "dicho3_result = pd.DataFrame.from_dict(dicho3_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "dicho3_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth Dichotomy: J or P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.713297</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.705611</td>\n",
       "      <td>0.916056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.677940</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.657955</td>\n",
       "      <td>0.980336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "LogisticRegression        0.713297     1.000000\n",
       "Perceptron                0.705611     0.916056\n",
       "DecisionTreeClassifier    0.677940     1.000000\n",
       "MultinomialNB             0.657955     0.980336"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test, dichotomy=4)\n",
    "dicho4_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "dicho4_result = pd.DataFrame.from_dict(dicho4_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "dicho4_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
